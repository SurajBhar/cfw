# Distributed Ray BOHB configuration
# Use with: python scripts/bayesian_optimize.py +optimization=bayesian_distributed

non_interactive: true

search_space:
  learning_rate:
    lower: 1e-5
    upper: 5e-2
    log: true

  weight_decay:
    lower: 1e-6
    upper: 1e-3
    log: true

  optimizer:
    choices: ["ADAM", "SGD"]

bohb:
  max_t: 50
  reduction_factor: 4
  stop_last_trials: true

tuner:
  num_samples: 24
  max_concurrent: 2
  metric: "val_balanced_accuracy"
  mode: "max"

ray:
  mode: cluster
  address: auto
  namespace: cfw-ray
  num_cpus: null
  num_gpus: null
  resources_per_trial:
    cpu: 4
    gpu: 1

storage:
  path: "./ray_results"
  name: "cfw_bohb_distributed"

checkpoints_to_keep: 3
evaluate_test_on_best: false
verbose: 1
